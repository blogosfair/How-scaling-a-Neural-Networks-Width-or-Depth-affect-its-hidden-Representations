<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="https://blogosfair.github.io/How-scaling-a-Neural-Networks-Width-or-Depth-affect-its-hidden-Representations/feed.xml" rel="self" type="application/atom+xml"/><link href="https://blogosfair.github.io/How-scaling-a-Neural-Networks-Width-or-Depth-affect-its-hidden-Representations/" rel="alternate" type="text/html" hreflang="en"/><updated>2023-02-02T17:17:40+00:00</updated><id>https://blogosfair.github.io/How-scaling-a-Neural-Networks-Width-or-Depth-affect-its-hidden-Representations/feed.xml</id><title type="html">ICLR Blogposts 2023 (staging)</title><subtitle>Staging website for the 2023 ICLR Blogposts track </subtitle><entry><title type="html">Sample Blog Post</title><link href="https://blogosfair.github.io/How-scaling-a-Neural-Networks-Width-or-Depth-affect-its-hidden-Representations/blog/2022/distill-example/" rel="alternate" type="text/html" title="Sample Blog Post"/><published>2022-12-01T00:00:00+00:00</published><updated>2022-12-01T00:00:00+00:00</updated><id>https://blogosfair.github.io/How-scaling-a-Neural-Networks-Width-or-Depth-affect-its-hidden-Representations/blog/2022/distill-example</id><content type="html" xml:base="https://blogosfair.github.io/How-scaling-a-Neural-Networks-Width-or-Depth-affect-its-hidden-Representations/blog/2022/distill-example/"><![CDATA[<h2 id="equations">Equations</h2> <p>This theme supports rendering beautiful math in inline and display modes using <a href="https://www.mathjax.org/">MathJax 3</a> engine. You just need to surround your math expression with <code class="language-plaintext highlighter-rouge">$$</code>, like <code class="language-plaintext highlighter-rouge">$$ E = mc^2 $$</code>. If you leave it inside a paragraph, it will produce an inline expression, just like \(E = mc^2\).</p> <p>To use display mode, again surround your expression with <code class="language-plaintext highlighter-rouge">$$</code> and place it as a separate paragraph. Here is an example:</p> \[\left( \sum_{k=1}^n a_k b_k \right)^2 \leq \left( \sum_{k=1}^n a_k^2 \right) \left( \sum_{k=1}^n b_k^2 \right)\] <p>Note that MathJax 3 is <a href="https://docs.mathjax.org/en/latest/upgrading/whats-new-3.0.html">a major re-write of MathJax</a> that brought a significant improvement to the loading and rendering speed, which is now <a href="http://www.intmath.com/cg5/katex-mathjax-comparison.php">on par with KaTeX</a>.</p> <h2 id="images-and-figures">Images and Figures</h2> <p>Its generally a better idea to avoid linking to images hosted elsewhere - links can break and you might face losing important information in your blog post. To include images in your submission in this way, you must do something like the following:</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{% include figure.html path="assets/img/2022-12-01-distill-example/iclr.png" class="img-fluid" %}
</code></pre></div></div> <p>which results in the following image:</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/How-scaling-a-Neural-Networks-Width-or-Depth-affect-its-hidden-Representations/assets/img/2022-12-01-distill-example/iclr-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/How-scaling-a-Neural-Networks-Width-or-Depth-affect-its-hidden-Representations/assets/img/2022-12-01-distill-example/iclr-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/How-scaling-a-Neural-Networks-Width-or-Depth-affect-its-hidden-Representations/assets/img/2022-12-01-distill-example/iclr-1400.webp"/> <img src="/How-scaling-a-Neural-Networks-Width-or-Depth-affect-its-hidden-Representations/assets/img/2022-12-01-distill-example/iclr.png" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>To ensure that there are no namespace conflicts, you must save your asset to your unique directory <code class="language-plaintext highlighter-rouge">/assets/img/2023-05-01-[SUBMISSION NAME]</code> within your submission.</p> <p>Please avoid using the direct markdown method of embedding images; they may not be properly resized. Some more complex ways to load images (note the different styles of the shapes/shadows):</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/How-scaling-a-Neural-Networks-Width-or-Depth-affect-its-hidden-Representations/assets/img/2022-12-01-distill-example/9-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/How-scaling-a-Neural-Networks-Width-or-Depth-affect-its-hidden-Representations/assets/img/2022-12-01-distill-example/9-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/How-scaling-a-Neural-Networks-Width-or-Depth-affect-its-hidden-Representations/assets/img/2022-12-01-distill-example/9-1400.webp"/> <img src="/How-scaling-a-Neural-Networks-Width-or-Depth-affect-its-hidden-Representations/assets/img/2022-12-01-distill-example/9.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/How-scaling-a-Neural-Networks-Width-or-Depth-affect-its-hidden-Representations/assets/img/2022-12-01-distill-example/7-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/How-scaling-a-Neural-Networks-Width-or-Depth-affect-its-hidden-Representations/assets/img/2022-12-01-distill-example/7-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/How-scaling-a-Neural-Networks-Width-or-Depth-affect-its-hidden-Representations/assets/img/2022-12-01-distill-example/7-1400.webp"/> <img src="/How-scaling-a-Neural-Networks-Width-or-Depth-affect-its-hidden-Representations/assets/img/2022-12-01-distill-example/7.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> A simple, elegant caption looks good between image rows, after each row, or doesn't have to be there at all. </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/How-scaling-a-Neural-Networks-Width-or-Depth-affect-its-hidden-Representations/assets/img/2022-12-01-distill-example/8-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/How-scaling-a-Neural-Networks-Width-or-Depth-affect-its-hidden-Representations/assets/img/2022-12-01-distill-example/8-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/How-scaling-a-Neural-Networks-Width-or-Depth-affect-its-hidden-Representations/assets/img/2022-12-01-distill-example/8-1400.webp"/> <img src="/How-scaling-a-Neural-Networks-Width-or-Depth-affect-its-hidden-Representations/assets/img/2022-12-01-distill-example/8.jpg" class="img-fluid z-depth-2" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/How-scaling-a-Neural-Networks-Width-or-Depth-affect-its-hidden-Representations/assets/img/2022-12-01-distill-example/10-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/How-scaling-a-Neural-Networks-Width-or-Depth-affect-its-hidden-Representations/assets/img/2022-12-01-distill-example/10-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/How-scaling-a-Neural-Networks-Width-or-Depth-affect-its-hidden-Representations/assets/img/2022-12-01-distill-example/10-1400.webp"/> <img src="/How-scaling-a-Neural-Networks-Width-or-Depth-affect-its-hidden-Representations/assets/img/2022-12-01-distill-example/10.jpg" class="img-fluid z-depth-2" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/How-scaling-a-Neural-Networks-Width-or-Depth-affect-its-hidden-Representations/assets/img/2022-12-01-distill-example/11-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/How-scaling-a-Neural-Networks-Width-or-Depth-affect-its-hidden-Representations/assets/img/2022-12-01-distill-example/11-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/How-scaling-a-Neural-Networks-Width-or-Depth-affect-its-hidden-Representations/assets/img/2022-12-01-distill-example/11-1400.webp"/> <img src="/How-scaling-a-Neural-Networks-Width-or-Depth-affect-its-hidden-Representations/assets/img/2022-12-01-distill-example/11.jpg" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/How-scaling-a-Neural-Networks-Width-or-Depth-affect-its-hidden-Representations/assets/img/2022-12-01-distill-example/12-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/How-scaling-a-Neural-Networks-Width-or-Depth-affect-its-hidden-Representations/assets/img/2022-12-01-distill-example/12-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/How-scaling-a-Neural-Networks-Width-or-Depth-affect-its-hidden-Representations/assets/img/2022-12-01-distill-example/12-1400.webp"/> <img src="/How-scaling-a-Neural-Networks-Width-or-Depth-affect-its-hidden-Representations/assets/img/2022-12-01-distill-example/12.jpg" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/How-scaling-a-Neural-Networks-Width-or-Depth-affect-its-hidden-Representations/assets/img/2022-12-01-distill-example/7-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/How-scaling-a-Neural-Networks-Width-or-Depth-affect-its-hidden-Representations/assets/img/2022-12-01-distill-example/7-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/How-scaling-a-Neural-Networks-Width-or-Depth-affect-its-hidden-Representations/assets/img/2022-12-01-distill-example/7-1400.webp"/> <img src="/How-scaling-a-Neural-Networks-Width-or-Depth-affect-its-hidden-Representations/assets/img/2022-12-01-distill-example/7.jpg" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <h3 id="interactive-figures">Interactive Figures</h3> <p>Here’s how you could embed interactive figures that have been exported as HTML files. Note that we will be using plotly for this demo, but anything built off of HTML should work (<strong>no extra javascript is allowed!</strong>). All that’s required is for you to export your figure into HTML format, and make sure that the file exists in the <code class="language-plaintext highlighter-rouge">assets/html/[SUBMISSION NAME]/</code> directory in this repository’s root directory. To embed it into any page, simply insert the following code anywhere into your page.</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{% include [FIGURE_NAME].html %} 
</code></pre></div></div> <p>For example, the following code can be used to generate the figure underneath it.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">plotly.express</span> <span class="k">as</span> <span class="n">px</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'https://raw.githubusercontent.com/plotly/datasets/master/earthquakes-23k.csv'</span><span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">px</span><span class="p">.</span><span class="n">density_mapbox</span><span class="p">(</span>
    <span class="n">df</span><span class="p">,</span> <span class="n">lat</span><span class="o">=</span><span class="s">'Latitude'</span><span class="p">,</span> <span class="n">lon</span><span class="o">=</span><span class="s">'Longitude'</span><span class="p">,</span> <span class="n">z</span><span class="o">=</span><span class="s">'Magnitude'</span><span class="p">,</span> <span class="n">radius</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">center</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">lat</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">lon</span><span class="o">=</span><span class="mi">180</span><span class="p">),</span> <span class="n">zoom</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">mapbox_style</span><span class="o">=</span><span class="s">"stamen-terrain"</span><span class="p">)</span>
<span class="n">fig</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">fig</span><span class="p">.</span><span class="n">write_html</span><span class="p">(</span><span class="s">'./assets/html/2022-12-01-distill-example/plotly_demo_1.html'</span><span class="p">)</span>
</code></pre></div></div> <p>And then include it with the following:</p> <div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">"l-page"</span><span class="nt">&gt;</span>
  <span class="nt">&lt;iframe</span> <span class="na">src=</span><span class="s">"{{ 'assets/html/2022-12-01-distill-example/plotly_demo_1.html' | relative_url }}"</span> <span class="na">frameborder=</span><span class="s">'0'</span> <span class="na">scrolling=</span><span class="s">'no'</span> <span class="na">height=</span><span class="s">"600px"</span> <span class="na">width=</span><span class="s">"100%"</span><span class="nt">&gt;&lt;/iframe&gt;</span>
<span class="nt">&lt;/div&gt;</span>
</code></pre></div></div> <p>Voila!</p> <div class="l-page"> <iframe src="/How-scaling-a-Neural-Networks-Width-or-Depth-affect-its-hidden-Representations/assets/html/2022-12-01-distill-example/plotly_demo_1.html" frameborder="0" scrolling="no" height="600px" width="100%"></iframe> </div> <h2 id="citations">Citations</h2> <p>Citations are then used in the article body with the <code class="language-plaintext highlighter-rouge">&lt;d-cite&gt;</code> tag. The key attribute is a reference to the id provided in the bibliography. The key attribute can take multiple ids, separated by commas.</p> <p>The citation is presented inline like this: <d-cite key="gregor2015draw"></d-cite> (a number that displays more information on hover). If you have an appendix, a bibliography is automatically created and populated in it.</p> <p>Distill chose a numerical inline citation style to improve readability of citation dense articles and because many of the benefits of longer citations are obviated by displaying more information on hover. However, we consider it good style to mention author last names if you discuss something at length and it fits into the flow well — the authors are human and it’s nice for them to have the community associate them with their work.</p> <hr/> <h2 id="footnotes">Footnotes</h2> <p>Just wrap the text you would like to show up in a footnote in a <code class="language-plaintext highlighter-rouge">&lt;d-footnote&gt;</code> tag. The number of the footnote will be automatically generated.<d-footnote>This will become a hoverable footnote.</d-footnote></p> <hr/> <h2 id="code-blocks">Code Blocks</h2> <p>This theme implements a built-in Jekyll feature, the use of Rouge, for syntax highlighting. It supports more than 100 languages. This example is in C++. All you have to do is wrap your code in a liquid tag:</p> <p>{% highlight c++ linenos %} <br/> code code code <br/> {% endhighlight %}</p> <p>The keyword <code class="language-plaintext highlighter-rouge">linenos</code> triggers display of line numbers. You can try toggling it on or off yourself below:</p> <figure class="highlight"><pre><code class="language-c--" data-lang="c++"><span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span> <span class="k">const</span> <span class="err">\</span><span class="o">*</span><span class="n">argv</span><span class="p">[])</span>
<span class="p">{</span>
<span class="n">string</span> <span class="n">myString</span><span class="p">;</span>

    <span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"input a string: "</span><span class="p">;</span>
    <span class="n">getline</span><span class="p">(</span><span class="n">cin</span><span class="p">,</span> <span class="n">myString</span><span class="p">);</span>
    <span class="kt">int</span> <span class="n">length</span> <span class="o">=</span> <span class="n">myString</span><span class="p">.</span><span class="n">length</span><span class="p">();</span>

    <span class="kt">char</span> <span class="n">charArray</span> <span class="o">=</span> <span class="k">new</span> <span class="kt">char</span> <span class="o">*</span> <span class="p">[</span><span class="n">length</span><span class="p">];</span>

    <span class="n">charArray</span> <span class="o">=</span> <span class="n">myString</span><span class="p">;</span>
    <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">length</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">){</span>
        <span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="n">charArray</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&lt;&lt;</span> <span class="s">" "</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span></code></pre></figure> <hr/> <h2 id="diagrams">Diagrams</h2> <p>This theme supports generating various diagrams from a text description using <a href="https://github.com/zhustec/jekyll-diagrams" target="\_blank">jekyll-diagrams</a> plugin. Below, we generate a few examples of such diagrams using languages such as <a href="https://mermaid-js.github.io/mermaid/" target="\_blank">mermaid</a>, <a href="https://plantuml.com/" target="\_blank">plantuml</a>, <a href="https://vega.github.io/vega-lite/" target="\_blank">vega-lite</a>, etc.</p> <p><strong>Note:</strong> different diagram-generation packages require external dependencies to be installed on your machine. Also, be mindful of that because of diagram generation the fist time you build your Jekyll website after adding new diagrams will be SLOW. For any other details, please refer to <a href="https://github.com/zhustec/jekyll-diagrams" target="\_blank">jekyll-diagrams</a> README.</p> <p><strong>Note:</strong> This is not supported for local rendering!</p> <p>The diagram below was generated by the following code:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{% mermaid %}
sequenceDiagram
    participant John
    participant Alice
    Alice-&gt;&gt;John: Hello John, how are you?
    John--&gt;&gt;Alice: Great!
{% endmermaid %}
</code></pre></div></div> <div class="jekyll-diagrams diagrams mermaid"> <svg id="mermaid-1675358273963" width="100%" xmlns="http://www.w3.org/2000/svg" height="100%" style="max-width:450px;" viewBox="-50 -10 450 231"><style>#mermaid-1675358273963 .label{font-family:trebuchet ms,verdana,arial;color:#333}#mermaid-1675358273963 .node circle,#mermaid-1675358273963 .node ellipse,#mermaid-1675358273963 .node polygon,#mermaid-1675358273963 .node rect{fill:#ececff;stroke:#9370db;stroke-width:1px}#mermaid-1675358273963 .node.clickable{cursor:pointer}#mermaid-1675358273963 .arrowheadPath{fill:#333}#mermaid-1675358273963 .edgePath .path{stroke:#333;stroke-width:1.5px}#mermaid-1675358273963 .edgeLabel{background-color:#e8e8e8}#mermaid-1675358273963 .cluster rect{fill:#ffffde!important;stroke:#aa3!important;stroke-width:1px!important}#mermaid-1675358273963 .cluster text{fill:#333}#mermaid-1675358273963 div.mermaidTooltip{position:absolute;text-align:center;max-width:200px;padding:2px;font-family:trebuchet ms,verdana,arial;font-size:12px;background:#ffffde;border:1px solid #aa3;border-radius:2px;pointer-events:none;z-index:100}#mermaid-1675358273963 .actor{stroke:#ccf;fill:#ececff}#mermaid-1675358273963 text.actor{fill:#000;stroke:none}#mermaid-1675358273963 .actor-line{stroke:grey}#mermaid-1675358273963 .messageLine0{marker-end:"url(#arrowhead)"}#mermaid-1675358273963 .messageLine0,#mermaid-1675358273963 .messageLine1{stroke-width:1.5;stroke-dasharray:"2 2";stroke:#333}#mermaid-1675358273963 #arrowhead{fill:#333}#mermaid-1675358273963 #crosshead path{fill:#333!important;stroke:#333!important}#mermaid-1675358273963 .messageText{fill:#333;stroke:none}#mermaid-1675358273963 .labelBox{stroke:#ccf;fill:#ececff}#mermaid-1675358273963 .labelText,#mermaid-1675358273963 .loopText{fill:#000;stroke:none}#mermaid-1675358273963 .loopLine{stroke-width:2;stroke-dasharray:"2 2";marker-end:"url(#arrowhead)";stroke:#ccf}#mermaid-1675358273963 .note{stroke:#aa3;fill:#fff5ad}#mermaid-1675358273963 .noteText{fill:#000;stroke:none;font-family:trebuchet ms,verdana,arial;font-size:14px}#mermaid-1675358273963 .section{stroke:none;opacity:.2}#mermaid-1675358273963 .section0{fill:rgba(102,102,255,.49)}#mermaid-1675358273963 .section2{fill:#fff400}#mermaid-1675358273963 .section1,#mermaid-1675358273963 .section3{fill:#fff;opacity:.2}#mermaid-1675358273963 .sectionTitle0,#mermaid-1675358273963 .sectionTitle1,#mermaid-1675358273963 .sectionTitle2,#mermaid-1675358273963 .sectionTitle3{fill:#333}#mermaid-1675358273963 .sectionTitle{text-anchor:start;font-size:11px;text-height:14px}#mermaid-1675358273963 .grid .tick{stroke:#d3d3d3;opacity:.3;shape-rendering:crispEdges}#mermaid-1675358273963 .grid path{stroke-width:0}#mermaid-1675358273963 .today{fill:none;stroke:red;stroke-width:2px}#mermaid-1675358273963 .task{stroke-width:2}#mermaid-1675358273963 .taskText{text-anchor:middle;font-size:11px}#mermaid-1675358273963 .taskTextOutsideRight{fill:#000;text-anchor:start;font-size:11px}#mermaid-1675358273963 .taskTextOutsideLeft{fill:#000;text-anchor:end;font-size:11px}#mermaid-1675358273963 .taskText0,#mermaid-1675358273963 .taskText1,#mermaid-1675358273963 .taskText2,#mermaid-1675358273963 .taskText3{fill:#fff}#mermaid-1675358273963 .task0,#mermaid-1675358273963 .task1,#mermaid-1675358273963 .task2,#mermaid-1675358273963 .task3{fill:#8a90dd;stroke:#534fbc}#mermaid-1675358273963 .taskTextOutside0,#mermaid-1675358273963 .taskTextOutside1,#mermaid-1675358273963 .taskTextOutside2,#mermaid-1675358273963 .taskTextOutside3{fill:#000}#mermaid-1675358273963 .active0,#mermaid-1675358273963 .active1,#mermaid-1675358273963 .active2,#mermaid-1675358273963 .active3{fill:#bfc7ff;stroke:#534fbc}#mermaid-1675358273963 .activeText0,#mermaid-1675358273963 .activeText1,#mermaid-1675358273963 .activeText2,#mermaid-1675358273963 .activeText3{fill:#000!important}#mermaid-1675358273963 .done0,#mermaid-1675358273963 .done1,#mermaid-1675358273963 .done2,#mermaid-1675358273963 .done3{stroke:grey;fill:#d3d3d3;stroke-width:2}#mermaid-1675358273963 .doneText0,#mermaid-1675358273963 .doneText1,#mermaid-1675358273963 .doneText2,#mermaid-1675358273963 .doneText3{fill:#000!important}#mermaid-1675358273963 .crit0,#mermaid-1675358273963 .crit1,#mermaid-1675358273963 .crit2,#mermaid-1675358273963 .crit3{stroke:#f88;fill:red;stroke-width:2}#mermaid-1675358273963 .activeCrit0,#mermaid-1675358273963 .activeCrit1,#mermaid-1675358273963 .activeCrit2,#mermaid-1675358273963 .activeCrit3{stroke:#f88;fill:#bfc7ff;stroke-width:2}#mermaid-1675358273963 .doneCrit0,#mermaid-1675358273963 .doneCrit1,#mermaid-1675358273963 .doneCrit2,#mermaid-1675358273963 .doneCrit3{stroke:#f88;fill:#d3d3d3;stroke-width:2;cursor:pointer;shape-rendering:crispEdges}#mermaid-1675358273963 .activeCritText0,#mermaid-1675358273963 .activeCritText1,#mermaid-1675358273963 .activeCritText2,#mermaid-1675358273963 .activeCritText3,#mermaid-1675358273963 .doneCritText0,#mermaid-1675358273963 .doneCritText1,#mermaid-1675358273963 .doneCritText2,#mermaid-1675358273963 .doneCritText3{fill:#000!important}#mermaid-1675358273963 .titleText{text-anchor:middle;font-size:18px;fill:#000}
#mermaid-1675358273963 g.classGroup text{fill:#9370db;stroke:none;font-family:trebuchet ms,verdana,arial;font-size:10px}#mermaid-1675358273963 g.classGroup rect{fill:#ececff;stroke:#9370db}#mermaid-1675358273963 g.classGroup line{stroke:#9370db;stroke-width:1}#mermaid-1675358273963 .classLabel .box{stroke:none;stroke-width:0;fill:#ececff;opacity:.5}#mermaid-1675358273963 .classLabel .label{fill:#9370db;font-size:10px}#mermaid-1675358273963 .relation{stroke:#9370db;stroke-width:1;fill:none}#mermaid-1675358273963 #compositionEnd,#mermaid-1675358273963 #compositionStart{fill:#9370db;stroke:#9370db;stroke-width:1}#mermaid-1675358273963 #aggregationEnd,#mermaid-1675358273963 #aggregationStart{fill:#ececff;stroke:#9370db;stroke-width:1}#mermaid-1675358273963 #dependencyEnd,#mermaid-1675358273963 #dependencyStart,#mermaid-1675358273963 #extensionEnd,#mermaid-1675358273963 #extensionStart{fill:#9370db;stroke:#9370db;stroke-width:1}#mermaid-1675358273963 .branch-label,#mermaid-1675358273963 .commit-id,#mermaid-1675358273963 .commit-msg{fill:#d3d3d3;color:#d3d3d3}</style><style>#mermaid-1675358273963{color:#000;font:normal normal 400 normal 16px / normal "Times New Roman"}</style><g></g><g><line id="actor0" x1="75" y1="5" x2="75" y2="220" class="actor-line" stroke-width="0.5px" stroke="#999"></line><rect x="0" y="0" fill="#eaeaea" stroke="#666" width="150" height="65" rx="3" ry="3" class="actor"></rect><text x="75" y="32.5" dominant-baseline="central" alignment-baseline="central" class="actor" style="text-anchor: middle;"><tspan x="75" dy="0">John</tspan></text></g><g><line id="actor1" x1="275" y1="5" x2="275" y2="220" class="actor-line" stroke-width="0.5px" stroke="#999"></line><rect x="200" y="0" fill="#eaeaea" stroke="#666" width="150" height="65" rx="3" ry="3" class="actor"></rect><text x="275" y="32.5" dominant-baseline="central" alignment-baseline="central" class="actor" style="text-anchor: middle;"><tspan x="275" dy="0">Alice</tspan></text></g><defs><marker id="arrowhead" refX="5" refY="2" markerWidth="6" markerHeight="4" orient="auto"><path d="M 0,0 V 4 L6,2 Z"></path></marker></defs><defs><marker id="crosshead" markerWidth="15" markerHeight="8" orient="auto" refX="16" refY="4"><path fill="black" stroke="#000000" stroke-width="1px" d="M 9,2 V 6 L16,4 Z" style="stroke-dasharray: 0, 0;"></path><path fill="none" stroke="#000000" stroke-width="1px" d="M 0,1 L 6,7 M 6,1 L 0,7" style="stroke-dasharray: 0, 0;"></path></marker></defs><g><text x="175" y="93" class="messageText" style="text-anchor: middle;">Hello John, how are you?</text><line x1="275" y1="100" x2="75" y2="100" class="messageLine0" stroke-width="2" stroke="black" marker-end="url(#arrowhead)" style="fill: none;"></line></g><g><text x="175" y="128" class="messageText" style="text-anchor: middle;">Great!</text><line x1="75" y1="135" x2="275" y2="135" class="messageLine1" stroke-width="2" stroke="black" marker-end="url(#arrowhead)" style="stroke-dasharray: 3, 3; fill: none;"></line></g><g><rect x="0" y="155" fill="#eaeaea" stroke="#666" width="150" height="65" rx="3" ry="3" class="actor"></rect><text x="75" y="187.5" dominant-baseline="central" alignment-baseline="central" class="actor" style="text-anchor: middle;"><tspan x="75" dy="0">John</tspan></text></g><g><rect x="200" y="155" fill="#eaeaea" stroke="#666" width="150" height="65" rx="3" ry="3" class="actor"></rect><text x="275" y="187.5" dominant-baseline="central" alignment-baseline="central" class="actor" style="text-anchor: middle;"><tspan x="275" dy="0">Alice</tspan></text></g></svg> </div> <hr/> <h2 id="tweets">Tweets</h2> <p>An example of displaying a tweet:</p> <div class="jekyll-twitter-plugin"><blockquote class="twitter-tweet"><p lang="sv" dir="ltr">jekyll-twitter-plugin (1.0.0): A Liquid tag plugin for Jekyll that renders Tweets from Twitter API <a href="http://t.co/m4EIQPM9h4">http://t.co/m4EIQPM9h4</a></p>&mdash; RubyGems (@rubygems) <a href="https://twitter.com/rubygems/status/518821243320287232?ref_src=twsrc%5Etfw">October 5, 2014</a></blockquote> <script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> </div> <p>An example of pulling from a timeline:</p> <div class="jekyll-twitter-plugin"><a class="twitter-timeline" data-width="500" data-tweet-limit="3" href="https://twitter.com/jekyllrb?ref_src=twsrc%5Etfw">Tweets by jekyllrb</a> <script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> </div> <p>For more details on using the plugin visit: <a href="https://github.com/rob-murray/jekyll-twitter-plugin">jekyll-twitter-plugin</a></p> <hr/> <h2 id="blockquotes">Blockquotes</h2> <blockquote> We do not grow absolutely, chronologically. We grow sometimes in one dimension, and not in another, unevenly. We grow partially. We are relative. We are mature in one realm, childish in another. —Anais Nin </blockquote> <hr/> <h2 id="layouts">Layouts</h2> <p>The main text column is referred to as the body. It is the assumed layout of any direct descendants of the <code class="language-plaintext highlighter-rouge">d-article</code> element.</p> <div class="fake-img l-body"> <p>.l-body</p> </div> <p>For images you want to display a little larger, try <code class="language-plaintext highlighter-rouge">.l-page</code>:</p> <div class="fake-img l-page"> <p>.l-page</p> </div> <p>All of these have an outset variant if you want to poke out from the body text a little bit. For instance:</p> <div class="fake-img l-body-outset"> <p>.l-body-outset</p> </div> <div class="fake-img l-page-outset"> <p>.l-page-outset</p> </div> <p>Occasionally you’ll want to use the full browser width. For this, use <code class="language-plaintext highlighter-rouge">.l-screen</code>. You can also inset the element a little from the edge of the browser by using the inset variant.</p> <div class="fake-img l-screen"> <p>.l-screen</p> </div> <div class="fake-img l-screen-inset"> <p>.l-screen-inset</p> </div> <p>The final layout is for marginalia, asides, and footnotes. It does not interrupt the normal flow of <code class="language-plaintext highlighter-rouge">.l-body</code> sized text except on mobile screen sizes.</p> <div class="fake-img l-gutter"> <p>.l-gutter</p> </div> <hr/> <h2 id="other-typography">Other Typography?</h2> <p>Emphasis, aka italics, with <em>asterisks</em> (<code class="language-plaintext highlighter-rouge">*asterisks*</code>) or <em>underscores</em> (<code class="language-plaintext highlighter-rouge">_underscores_</code>).</p> <p>Strong emphasis, aka bold, with <strong>asterisks</strong> or <strong>underscores</strong>.</p> <p>Combined emphasis with <strong>asterisks and <em>underscores</em></strong>.</p> <p>Strikethrough uses two tildes. <del>Scratch this.</del></p> <ol> <li>First ordered list item</li> <li>Another item ⋅⋅* Unordered sub-list.</li> <li>Actual numbers don’t matter, just that it’s a number ⋅⋅1. Ordered sub-list</li> <li>And another item.</li> </ol> <p>⋅⋅⋅You can have properly indented paragraphs within list items. Notice the blank line above, and the leading spaces (at least one, but we’ll use three here to also align the raw Markdown).</p> <p>⋅⋅⋅To have a line break without a paragraph, you will need to use two trailing spaces.⋅⋅ ⋅⋅⋅Note that this line is separate, but within the same paragraph.⋅⋅ ⋅⋅⋅(This is contrary to the typical GFM line break behaviour, where trailing spaces are not required.)</p> <ul> <li>Unordered list can use asterisks</li> <li>Or minuses</li> <li>Or pluses</li> </ul> <p><a href="https://www.google.com">I’m an inline-style link</a></p> <p><a href="https://www.google.com" title="Google's Homepage">I’m an inline-style link with title</a></p> <p><a href="https://www.mozilla.org">I’m a reference-style link</a></p> <p><a href="../blob/master/LICENSE">I’m a relative reference to a repository file</a></p> <p><a href="http://slashdot.org">You can use numbers for reference-style link definitions</a></p> <p>Or leave it empty and use the <a href="http://www.reddit.com">link text itself</a>.</p> <p>URLs and URLs in angle brackets will automatically get turned into links. http://www.example.com or <a href="http://www.example.com">http://www.example.com</a> and sometimes example.com (but not on Github, for example).</p> <p>Some text to show that the reference links can follow later.</p> <p>Here’s our logo (hover to see the title text):</p> <p>Inline-style: <img src="https://github.com/adam-p/markdown-here/raw/master/src/common/images/icon48.png" alt="alt text" title="Logo Title Text 1"/></p> <p>Reference-style: <img src="https://github.com/adam-p/markdown-here/raw/master/src/common/images/icon48.png" alt="alt text" title="Logo Title Text 2"/></p> <p>Inline <code class="language-plaintext highlighter-rouge">code</code> has <code class="language-plaintext highlighter-rouge">back-ticks around</code> it.</p> <div class="language-javascript highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">var</span> <span class="nx">s</span> <span class="o">=</span> <span class="dl">"</span><span class="s2">JavaScript syntax highlighting</span><span class="dl">"</span><span class="p">;</span>
<span class="nx">alert</span><span class="p">(</span><span class="nx">s</span><span class="p">);</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">s</span> <span class="o">=</span> <span class="s">"Python syntax highlighting"</span>
<span class="k">print</span> <span class="n">s</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>No language indicated, so no syntax highlighting. 
But let's throw in a &lt;b&gt;tag&lt;/b&gt;.
</code></pre></div></div> <p>Colons can be used to align columns.</p> <table> <thead> <tr> <th>Tables</th> <th style="text-align: center">Are</th> <th style="text-align: right">Cool</th> </tr> </thead> <tbody> <tr> <td>col 3 is</td> <td style="text-align: center">right-aligned</td> <td style="text-align: right">$1600</td> </tr> <tr> <td>col 2 is</td> <td style="text-align: center">centered</td> <td style="text-align: right">$12</td> </tr> <tr> <td>zebra stripes</td> <td style="text-align: center">are neat</td> <td style="text-align: right">$1</td> </tr> </tbody> </table> <p>There must be at least 3 dashes separating each header cell. The outer pipes (|) are optional, and you don’t need to make the raw Markdown line up prettily. You can also use inline Markdown.</p> <table> <thead> <tr> <th>Markdown</th> <th>Less</th> <th>Pretty</th> </tr> </thead> <tbody> <tr> <td><em>Still</em></td> <td><code class="language-plaintext highlighter-rouge">renders</code></td> <td><strong>nicely</strong></td> </tr> <tr> <td>1</td> <td>2</td> <td>3</td> </tr> </tbody> </table> <blockquote> <p>Blockquotes are very handy in email to emulate reply text. This line is part of the same quote.</p> </blockquote> <p>Quote break.</p> <blockquote> <p>This is a very long line that will still be quoted properly when it wraps. Oh boy let’s keep writing to make sure this is long enough to actually wrap for everyone. Oh, you can <em>put</em> <strong>Markdown</strong> into a blockquote.</p> </blockquote> <p>Here’s a line for us to start with.</p> <p>This line is separated from the one above by two newlines, so it will be a <em>separate paragraph</em>.</p> <p>This line is also a separate paragraph, but… This line is only separated by a single newline, so it’s a separate line in the <em>same paragraph</em>.</p>]]></content><author><name>Albert Einstein</name></author><summary type="html"><![CDATA[Your blog post's abstract. This is an example of a distill-style blog post and the main elements it supports.]]></summary></entry><entry><title type="html">How scaling a neural networks width or depth affect its hidden representations</title><link href="https://blogosfair.github.io/How-scaling-a-Neural-Networks-Width-or-Depth-affect-its-hidden-Representations/blog/2022/how-scaling-a-neural-networks-width-or-depth-affect-its-hidden-representations/" rel="alternate" type="text/html" title="How scaling a neural networks width or depth affect its hidden representations"/><published>2022-12-01T00:00:00+00:00</published><updated>2022-12-01T00:00:00+00:00</updated><id>https://blogosfair.github.io/How-scaling-a-Neural-Networks-Width-or-Depth-affect-its-hidden-Representations/blog/2022/how-scaling-a-neural-networks-width-or-depth-affect-its-hidden-representations</id><content type="html" xml:base="https://blogosfair.github.io/How-scaling-a-Neural-Networks-Width-or-Depth-affect-its-hidden-Representations/blog/2022/how-scaling-a-neural-networks-width-or-depth-affect-its-hidden-representations/"><![CDATA[<h2 id="introduction">Introduction</h2> <p>When applying artificial neural networks, performance can be optimized by varying the architecture depth and width. However, there is a lack of understanding of what effect scaling the models’ main parameters - depth and width - has on the learned representations. Do deep models learn different hidden layer features than wide models? Also, are there systematical differences in the outputs of deep and wide models?</p> <p>This lack of insight is tackled in the paper</p> <p></p> <p><span>   ▶  </span>Thao Nguyen et al. (ICLR, 2021) Do Wide and Deep Networks Learn the Same Things? Uncovering How Neural Network Representations Vary with Width and Depth <d-cite key="DBLP:conf/iclr/NguyenRK21"></d-cite>.</p> <p></p> <p>First, representation similarity is analyzed between different layers of a single model. It is found that in overparameterized models, so-called <em>block structures</em> arise, which refer to groups of contiguous layers which have very similar hidden representations. These block structures emerge independent of whether a model’s width or depth is increased.<br/> Furthermore, it is shown that key components of the representations are preserved and propagated during block structure layers. This opens various questions:</p> <ul> <li>Are representations becoming more meaningful for the task at hand when being propagated through the block structure?</li> <li>Could block structure layers be pruned from the model without negatively affecting performance?</li> <li>What role do the residual connections, present in the models used in the experiments, play for keeping representations similar during propagation through the block structure?</li> </ul> <p>Those questions are addressed by Nguyen et al. <d-cite key="DBLP:conf/iclr/NguyenRK21"></d-cite>, and their answers will be discussed and interactively visualized in the the following blogpost.</p> <p>In addition, the blogpost presents novel findings described by the second part of Nguyen et al. <d-cite key="DBLP:conf/iclr/NguyenRK21"></d-cite>’s analysis, which deals with representation similarities between different models, as well as whether models of different architecture type (e.g. deep vs. wide) show systematical differences in output predictions, despite performing very similar overall.</p> <h2 id="centered-kernel-alignment">Centered kernel alignment</h2> <p>Let’s begin with having a look at methodology. It is not that easy to directly compare different layers representations, for example because of their varying size and their distributed nature (meaning that important features can rely on different neurons outputs). The tool Nguyen et al. <d-cite key="DBLP:conf/iclr/NguyenRK21"></d-cite> use for measuring representation similarity, is called centered kernel alignment (CKA) <d-footnote>Note that Nguyen et al. <d-cite key="DBLP:conf/iclr/NguyenRK21"></d-cite> propose a slightly modified version of CKA in their paper, namely minibatch CKA, which is used in their experiments. They modify classic CKA to reduce memory consumption, and their minibatch CKA converges to the same value as CKA when the whole dataset is considered a minibatch.</d-footnote>, and addresses those problems.<br/> It follows a straight forward idea, which originates in neuroscience: Similarity is not measured between representations directly, but between representation (dis-)similarity matrices</p> <d-cite key="kriegeskorte2008representational"></d-cite> <p>.</p> <style>#floated{float:left}</style> <p>When $\mathbf{X}$ is a matrix, holding the encoded features of size $m \times p_1$ ($m$ being the number of examples, $p_1$ being the number of neurons), then $\mathbf{K}=\mathbf{XX}^\top$ refers to the $m \times m$ <ins>representation similarity matrix</ins> of our first comparison layer. We can now compare how similar $\mathbf{K}$ is to a second representation similarity matrix $\mathbf{L} = \mathbf{Y}\mathbf{Y}^\top$, with $\mathbf{Y}$ of size $m \times p_2$ holding the examples encoded after our second comparison layer.<br/> In words, we do not compare representations, but how similar the relations between each layers representations are.</p> <p>Proceeding to CKA, not a lot of logic is added. First, both representation similarity matrices have to be centered (column and row means are being subtracted). This is done by computing $\mathbf{K}’ = \mathbf{HKH}$, with $\mathbf{H}$ being the centering matrix $\mathbf{H} = \mathbf{I}_n - \frac{1}{n} \boldsymbol{1}\boldsymbol{1}^\top$. In this case, $n$ equals $m$, and $\mathbf{L}’$ is computed accordingly. The similarity between $\mathbf{K}’$ and $\mathbf{L}’$ is then calculated using the Hilbert-Schmidt Independence Criterion (HSIC). More specifically, $\textrm{HSIC} (\mathbf{K}, \mathbf{L})= \textrm{vec}(\mathbf{K}’)\textrm{vec}(\mathbf{L}’)/(m-1)^2$, which is a measure invariant to orthogonal transformations, and thus to permutations of neurons <d-cite key="DBLP:conf/icml/Kornblith0LH19"></d-cite>. Finally, CKA normalizes $\textrm{HSIC}$ to make the similarity score invariant to isotropic scaling, and to get a nice range of values between 0 and 1.</p> <p>Finally, the CKA formula is:</p> \[\begin{equation} \textrm{CKA}(\mathbf{K}, \mathbf{L}) = \frac{\textrm{HSIC} (\mathbf{K'}, \mathbf{L'})}{\sqrt{\textrm{HSIC} (\mathbf{K}, \mathbf{K}) \textrm{HSIC} (\mathbf{L}, \mathbf{L})}}. \end{equation}\] <h2 id="block-structure">Block structure</h2> <p>The first part of the paper deals with representation structure within models when scaling their with and depth. Nguyen et al. <d-cite key="DBLP:conf/iclr/NguyenRK21"></d-cite> train different variants of ResNets <d-cite key="DBLP:conf/cvpr/HeZRS16"></d-cite>, mostly on CIFAR-10, and calculate the CKA score for each pair of the models layers. Those are then visualized in heatmaps as seen below. Three notes on this:</p> <ul> <li>The models compared within a graphic perform very similarly, with the maximum test accuracy margin between two models being 1,9%.</li> <li>The number of layers indicated in the plot might be bigger than the number of layers indicated in the models name. This is due to the fact, that in the plots it is accounted not only for the convolutional layers, but for all intermediate representations. Additional representations e.g. arise through pooling layers.</li> <li>The chessboard like structure arises as a result of the residual connections: Representations after a residual connection are more similar to other post-residual representations, than to representations within a residual block.</li> </ul> <p>The first major finding in the paper, is that with increased width or depth of models, blocks of contiguous layers with a very high representation similarity arise. With the capacity of the models increasing, the blocks tend to get larger and more distinct. One can see the phenomenon emerge in the graphic below:</p> <div class="l-page"> <iframe src="/How-scaling-a-Neural-Networks-Width-or-Depth-affect-its-hidden-Representations/assets/html/2022-12-01-how-scaling-a-neural-networks-width-or-depth-affect-its-hidden-representations/slider1.html" frameborder="0" scrolling="no" height="600px" width="100%"></iframe> </div> <p align="center" style="margin-top:20px"> <em> Figure 1: The block structures emerge when increasing the models depth (left) or width (right). </em> </p> <p>A block of contiguous layers, with CKA scores close to one, is termed <em>block structure</em>. It is visible that block structures arise independently of whether the models with or depth are increased.</p> <p>Next, it is investigated whether the block structures emerge with regard to absolute model size, or model size relative to the data. Nguyen et al. <d-cite key="DBLP:conf/iclr/NguyenRK21"></d-cite> proceed by training models, with gradually reduced training data, while keeping the other model parameters static. The results can be explored below:</p> <div class="l-page"> <iframe src="/How-scaling-a-Neural-Networks-Width-or-Depth-affect-its-hidden-Representations/assets/html/2022-12-01-how-scaling-a-neural-networks-width-or-depth-affect-its-hidden-representations/fig_2.html" frameborder="0" scrolling="no" height="600px" width="100%"></iframe> </div> <p align="center" style="margin-top:20px"> <em> Figure 2: Reducing the training data leads to block structures emerging in models with less capacity. </em> </p> <p>It can be seen, that when reducing the data step by step, the blocks structures emerge in smaller models already, for both deep and wide models. Therefore, it is concluded, that the emergence of the block structure seems to be an artifact of overparameterized models.</p> <h3 id="what-happens-within-block-structures">What happens within block structures?</h3> <p>After gaining knowledge about the block structure, the consequent follow-up question is, what happens to the representations within the block structure. Revisiting how the CKA score was computed, note the two-step procedure that was used: First, representation similarity matrices were computed (for each layer in this case), which were then compared with other representation similarity matrices. This means that representations can numerically change between layers, however, the CKA score between those layers remains high in case the relative representation structure remains similar.</p> <p>So, what computations are done by the neural networks during block structure layers? For investigating, Nguyen et al. <d-cite key="DBLP:conf/iclr/NguyenRK21"></d-cite> look at a rewritten version of the CKA score. When $\mathbf{X}$ and $\mathbf{Y}$, of sizes $n \times p_1$ and $n \times p_2$, hold the centered layer representations, the CKA score can be computed using the following formular:</p> \[\begin{equation} \textrm{CKA}(\mathbf{XX}^\top, \mathbf{YY}^\top) = \frac{\sum_{i=1}^{p_1} \sum_{j=1}^{p_2} \lambda_{X}^i \lambda_{Y}^j \langle \mathbf{u}_{X}^i\,,\mathbf{u}_{Y}^j\rangle^2} {\sqrt{\sum_{i=1}^{p_1} (\lambda_{X}^i)^2} \sqrt{\sum_{j=1}^{p_2} (\lambda_{Y}^j)^2}}. \end{equation}\] <p>The equation arises by rewriting $\mathbf{X}$ and $\mathbf{Y}$ in terms of their in terms of their singular value decompositions</p> <d-cite key="DBLP:conf/icml/Kornblith0LH19"></d-cite> <p>. The vectors \(\begin{equation}\mathbf{u}_{X}^i\end{equation}\) and \(\begin{equation} \mathbf{u}_{Y}^j \end{equation}\) refer to the \(\begin{equation} i^{\textrm{th}} \end{equation}\)/\(\begin{equation} j^{\textrm{th}}\end{equation}\) left-singular vector of \(\begin{equation} \mathbf{XX}^\top \end{equation}\)/\(\begin{equation} \mathbf{YY}^\top \end{equation}\), which refer to the normalized principle components of $\mathbf{X}$ and $\mathbf{Y}$ <d-cite key="DBLP:conf/iclr/NguyenRK21"></d-cite>. Finally, $\lambda_{X}^i$ and $\lambda_{Y}^j$ are the corresponding squared singular values, which measure the fraction of variance explained by each principal component in the representations.</p> <p>Nguyen et al. <d-cite key="DBLP:conf/iclr/NguyenRK21"></d-cite> find, that the fraction of variance, that is explained by the first principal component, is very high in network layers within a block structure, but low for other layers.</p> <p>If for two layers, all the variance in the representations would be explained by their first principal components, the CKA score between those layers would collapse to the squared alignment \(\begin{equation} \langle \mathbf{u}_{X}^i\,,\mathbf{u}_{Y}^j\rangle^2\end{equation}\) between those first principal components. It is thus suggested, that within block structure layers, where the CKA score is continuously close to 1, the first principal component is <em>preserved</em> and <em>propagated</em>.</p> <p>This theoretical finding is supported by analysing previously shown models with regard to the first principal component:</p> <div class="l-page"> <iframe src="/How-scaling-a-Neural-Networks-Width-or-Depth-affect-its-hidden-Representations/assets/html/2022-12-01-how-scaling-a-neural-networks-width-or-depth-affect-its-hidden-representations/fig_3.html" frameborder="0" scrolling="no" height="600px" width="100%"></iframe> </div> <p align="center" style="margin-top:20px"> <em> Figure 3: Four plots, for four different models: A deep model with block structure (left), a deep model without block structure (left, after clicking the 'No blocks' button), a wide model with block structure (right) and a wide model without block structure (right, after clicking the 'No blocks' button"). On the top right for each model, the CKA heatmap is plotted as usual. On the top left, the cosine similarity for each layers first principal component can be seen. The bottom left shows the variance explained in the representations by the first principal component of each layer. The bottom right shows the CKA heatmap for layers with the first principal component being deleted from the representation matrices. </em> </p> <p>In the bottom left, we can see the fraction of variance explained in the representations by the first principal component, per layer. Looking at the models exhibiting a block structure, it is very visible that the fraction of variance explained within the block structures is greatly larger than in non block structure layers. When swapping to models without a block structure, this difference becomes even more clear.</p> <p>The top-left plot shows the cosine similarity between the first principal components. We can see that for models exhibiting a block structure, the heat map looks very similar to the CKA score plotted top-right, which showcases that CKA reflects the alignment between the first principal components, if the fractions of variance explained by them approach 1. Looking at non block structure models, the CKA heatmap is visibly different from the heatmap comparing first principal components.</p> <p>Finally, the CKA heatmap for models with the first principal component removed from the representations is shown at the bottom right. For the overparameterized models, this removes the block structure from the heatmap. For the non block structure models, the heatmap remains mostly unchanged.</p> <p>“Together these results demonstrate that the block structure arises from preserving and propagating the first principal component across its constituent layers.” <d-cite key="DBLP:conf/iclr/NguyenRK21"></d-cite>.</p> <p>Furthermore, all effects seem to be similar for the left and the right side, disregarding whether the models overparameterizations come from increased width or depth.</p> <h3 id="are-block-structures-useful">Are block structures useful?</h3> <p>While representations stay relatively similar in their relations to each other, when being propagated through the block structure, one could still ask whether transformations applied within block structures impact task performance.<br/> For investigating this question, Nguyen et al. <d-cite key="DBLP:conf/iclr/NguyenRK21"></d-cite> train linear probes after each layer of different models. A linear probe resembles a linear classifier, that maps directly from layers hidden representations to input examples labels <d-cite key="DBLP:conf/iclr/AlainB17"></d-cite>. Linear probe accuracies can be seen below, for two models with block structure, and two without. Note that two models of the same architecture type can exhibit different CKA heatmaps, due to their different initializations.</p> <div class="l-page"> <iframe src="/How-scaling-a-Neural-Networks-Width-or-Depth-affect-its-hidden-Representations/assets/html/2022-12-01-how-scaling-a-neural-networks-width-or-depth-affect-its-hidden-representations/fig_4.html" frameborder="0" scrolling="no" height="600px" width="100%"></iframe> </div> <p align="center" style="margin-top:20px"> <em> Figure 4: Top row: CKA heatmaps for models with different widths. Bottom row: Linear probe accuracy for each layer. The dashed green lines refer to the boundaries between ResNet stages. </em> </p> <p>For the models without block structures on the left, we can see the accuracy of the linear probes monotonically increasing, and with it the informativity of the hidden representations regarding the task at hand. For models exhibiting block structures on the right, the picture looks more complex: For layers within a block, and before a residual connection, the linear probe accuracy drops noticeably. For within block layers, after a residual connection, the accuracy increases only marginally.<br/> Also, there seems to be a jump in linear probe accuracy at the post-residual connection before the block structure, and one in the very early layers, for both models on the right. It feels though, that in overparameterized, block structure models, more of the relevant logic is performed in individual layers. Other layers, especially during block structures, seem to mostly propagate information from previous layers. Furthermore, this propagation seems to heavily rely on the residual connections present in ResNets, as pre-residual layers within blocks seem to even worsen the representations.</p> <p>For researching the dynamics between block structure emergence and residual connections, Nguyen et al. <d-cite key="DBLP:conf/iclr/NguyenRK21"></d-cite> trained plain convolutional neural networks, without residual connections with varying widths, and computed the corresponding CKA heatmaps:</p> <div class="l-page"> <iframe src="/How-scaling-a-Neural-Networks-Width-or-Depth-affect-its-hidden-Representations/assets/html/2022-12-01-how-scaling-a-neural-networks-width-or-depth-affect-its-hidden-representations/fig_1b.html" frameborder="0" scrolling="no" height="600px" width="100%"></iframe> </div> <p align="center" style="margin-top:20px"> <em> Figure 5: Block structures emerge in a model without residual connections with increased width. </em> </p> <p>As shown for different ResNets, one can see blocks arise with increased model capacity. Based on the above graphic, Nguyen et al. <d-cite key="DBLP:conf/iclr/NguyenRK21"></d-cite> conclude that the emergence of block structures does not seem to be affected by the residual connections.<br/> When carefully observing the pictures, however, there are differences to the block structures seen in the ResNets:</p> <ul> <li>The blocks are not as sharp at the borders, and also the CKA score within the blocks is not uniformly as high as in the block structures observed in overparameterized ResNets.</li> <li>When further increasing the model capacity, after block structures already emerged, blocks do not seem to change much anymore. Again, this is different to what was observed before in the ResNets, where the position and especially the size of the block structures kept changing.</li> </ul> <p>Finally, it still seems that the residual connections do play a role for the emergence, and especially nature of block structures. More on this can be read in our discussion.</p> <h3 id="collapsing-the-block-structure">Collapsing the block structure</h3> <p>We’ve seen that the block structure arises in overparameterized models, and also that it preserves and propagates key components of the representations. Also, we’ve seen that the amount of task relevant information in the representations barely rises during the block structure.<br/> Another way of researching whether/how much block structure layers are contributing in solving the final task, is simply pruning block structure layers from the model, and see whether the final performance is affected. Nguyen et al. <d-cite key="DBLP:conf/iclr/NguyenRK21"></d-cite> proceed to do exactly this, and for comparison, also non block structure layers are pruned from the models.<br/> More precisely, ResNet blocks are deleted one-by-one, starting at the end of each ResNet stage. How this impacts the performance of models can be seen below, for two models that exhibit block structure, and two that do not:</p> <div class="l-page"> <iframe src="/How-scaling-a-Neural-Networks-Width-or-Depth-affect-its-hidden-Representations/assets/html/2022-12-01-how-scaling-a-neural-networks-width-or-depth-affect-its-hidden-representations/fig_5.html" frameborder="0" scrolling="no" height="600px" width="100%"></iframe> </div> <p align="center" style="margin-top:20px"> <em> Figure 6: Top row: CKA heatmaps for two narrow models (trained from different initializations) and two wide models. Bottom row: Test accuracy after deleting blocks from the end of each ResNet stage (indicated by the green dashed lines), while keeping the residual connections intact. The grey dashed line refers to the original models performance. </em> </p> <p>One can see that pruning blocks from the middle ResNet stage, and within a block structure, leads to only a small loss of overall performance. Furthermore, the size of the block structure seems to play a role: the performance loss in the second model from the right (large block structure) is even smaller than in the most right model (smaller block structure). When pruning residual blocks from other parts of the models, as well as in models without block structures, the performance loss is mostly pretty drastic.</p> <p>After two experiments researching the dynamics between block structure layers and final task performance, it forms the intuition that block structure layers seem to contribute little to the models overall performance. In more pronounced block structures, the block structure layers contribution to final performance seems to approach zero.</p> <h2 id="cross-model-dynamics">Cross model dynamics</h2> <p>Next, the similarity of representations between different models is investigated. Nguyen et al. <d-cite key="DBLP:conf/iclr/NguyenRK21"></d-cite> compare how similar the representations of architecturally identical models, with different initializations, and how similar the representations of models with different architectures are. Again, the models compared exhibit a very similar testing accuracy.</p> <p>For models without block structures, the CKA heatmaps between layers of different models look very similar to the heatmaps between layers of the same model. This holds for when architecturally identical models are compared, as well as when architecturally different models are compared. In the latter case, the representations are still similar along the diagonal of the heatmap, suggesting similar representations at the same relative model depth.</p> <p>For models exhibiting block structures, there is some representation similarity for non block structure layers. However, when comparing layers of different models from which at least one layer is part of a block structure, in the within model heatmap, there is nearly no to no representation similarity at all. Representations during block structures therefore seem unique to each model.</p> <h2 id="effect-of-depth-and-width-on-the-models-outputs">Effect of depth and width on the models outputs</h2> <p>Finally, Nguyen et al. <d-cite key="DBLP:conf/iclr/NguyenRK21"></d-cite> have investigated how model architectures and model outputs relate. They found that there are systematically different output predictions made by different model types, even though the average accuracy is very similar. The outputs are systematically different on class level, as well as on individual example level. Let’s have a look at the graphics below, to see those findings in detail:</p> <div class="l-page"> <iframe src="/How-scaling-a-Neural-Networks-Width-or-Depth-affect-its-hidden-Representations/assets/html/2022-12-01-how-scaling-a-neural-networks-width-or-depth-affect-its-hidden-representations/fig_6.html" frameborder="0" scrolling="no" height="600px" width="100%"></iframe> </div> <p align="center" style="margin-top:20px"> <em> Figure 7: Left side: Comparison of example level accuracy of two groups of 100 networks each, trained on CIFAR-10. <strong>b</strong>: Two groups of ResNet-62 models compared for showcasing the variance in example level predictions that occurs by chance. <strong>a</strong>: A group of ResNet-14 (2x) compared with a group of ResNet-62s. One can see that the variance is much higher than in the left bottom plot. <strong>c</strong>: Comparison of testing accuracies for different groups of models trained on ImageNet, this time on class level. Orange dots: baseline comparison between ResNet-83 groups. Blue dots: Group of ResNet-83s and ResNet-50 (x2.8). </em> </p> <p>On the left bottom side of the plot (<strong>b</strong>), we can see the average accuracy for individual examples, of two groups of 100 deep ResNets, on the CIFAR-10 test set. Note that both groups have statistically indistinguishable average accuracies on the whole dataset. The graphic acts as a baseline, to show what amount of variance between two groups of models should be expected by chance. For comparison, on the top left (<strong>a</strong>), average individual example accuracies are shown for a group of wide models and a group of deep models. We can see that the individual example accuracies vary much more than in the top left plot, which indicates that wide and deep models make systematically different mistakes.</p> <p>Insights in systematic differences in model outputs on class level, are shown on the right side of the figure. This time, the class level accuracies of two groups of architectually identical deep models are compared as a baseline (orange dots), with ImageNet being the dataset. The blue dots compare a group of deep models and a group of wide models. Again, one can see that there are systematic differences in output predictions, this time on class level. Looking at individual classes, three out of the five classes where the group of wide models perform better, resemble scenes: seashore, library and book store. Following this intuition, Nguyen et al. <d-cite key="DBLP:conf/iclr/NguyenRK21"></d-cite> find that the wide models significantly perform better on ImageNet classes that descend from “structure” or “geological formation”. Note that while the difference in accuracy is statistically significant, it is quite small ($74.9\% \pm 0.05 \ \mathrm{vs.} \ 74.6\% \pm 0.06$). Deep models on the other hand, performed significantly better on classes descending from “consumer goods”, again with a relatively small margin though ($72.4\% \pm 0.07 \ \mathrm{vs.} \ 72.1\% \pm 0.06$).</p> <p>In the reviewing process, Nguyen et al. <d-cite key="DBLP:conf/iclr/NguyenRK21"></d-cite> hypothesize that wide layers might be better at capturing small details which would help when detecting scenes, while depth would help when global structure is important, which would help with consumer goods.</p> <h2 id="discussion">Discussion</h2> <p>Nguyen et al. <d-cite key="DBLP:conf/iclr/NguyenRK21"></d-cite> have shown that a so called block structure arises in overparameterized models, no matter if they are deep or wide. A block structure consists of many contiguous neural network layers, whose representations show very high similarity. They found that within a block structure, the first principal component of the layers representation matrix is mainly propagated.<br/> They proceed by relating block structure and task performance, and find that the task-informativity of representations barely rises during block structures. Also, it becomes visible that residual connections play an important role when propagating information through block structure layers.<br/> Next, ResNet blocks were pruned from block structure models, and it was shown that block structure layers could be deleted from models with minimal performance loss during the middle stage of the ResNet.<br/> When comparing different models representations, it was found that representations are similar regarding the relative depth of models with different architecture types. Representations within block structures, however, didn’t exhibit similarity with representations from layers of other models.<br/> Finally, they look at the relation between model architectures and model outputs, and find that there are systematical different mistakes made by models of different architecture types. This is observed on individual example level and on class level, and even though the compared models performance is very similar on the whole dataset.</p> <p>A first point of discussion, is the dynamic between residual connections and the block structure. While Figure 5 shows that a block structure can also arise in a model without residual connections, there are differences in shape and delimitability. More specifically, the block structure arising in the CNN seems less clear, and also, it doesn’t increase size or clarity when increasing the model capacity further and further. Also, the linear probe experiment shown in Figure 4 showcases the importance of residual connections for keeping the representations task relevance throughout the block structure.<br/> It remains a topic of research, thus, how well the findings about the nature of the block structure generalize to different architecture types. A hypothesis might be, that when unnecessarily increasing the model capacity of a ResNet, the flow of information relies more and more on the residual connections, which propagate previously acquired logic in the representations.<br/> In contrast, the block structure layers of the CNN have to preserve the representations themselves, so e.g. a drop in task usefulness like seen for the pre-residual layers within a block structure in Figure 4, would probably not be observed. A continuous (but probalby small) rise in linear probe accuracy throughout the block structure CNNs seems more imaginable, and it would indicate a major difference in the nature of block structure layers in ResNets and non-residual models.</p> <p>Next, it remains the questions whether the block structure benefits overall models performance. When looking at Figure 4 again, we can see that the linear probe accuracy still slightly increases in layers within a block structure, after a residual connection. Furthermore, Nguyen et al. <d-cite key="DBLP:conf/iclr/NguyenRK21"></d-cite> present a table with each models test performance, and while accuracy seems to saturate at some capacity, large models still perform better than smaller models in nearly all cases, even though the large models exhibit massive block structures.<br/> Also, it was shown in Figure 6, that pruning layers from the block structure in the middle stage reduces accuracy, however, only slightly. The accuracy seemed to decrease less, when the block structure was greater and more pronounced.<br/> It seems though, that some useful transformations are still going on within block structures, however, the transformations turn less useful as the overparameterization increases.</p> <p>For practical purposes of the presented findings, neural architecture search/model design would be the field to benefit: Information about emerging block structures could be used to find a trade-off between efficient, and successful neural architecture search. Detecting a block structures indicates being in the overparameterized regime, meaning that training a less capacity model might yield a similar performance.</p> <p>Also, a direction of thought could be designing networks that prevent themselves from building blocks, e.g. through penalizing representation similarity in the loss. The idea would be, to still fight vanishing/exploding gradients using skip-connections</p> <d-cite key="DBLP:conf/cvpr/SzegedyLJSRAEVR15"></d-cite> <p>, while preventing the net from simply propagating information during block structures.<br/> Whether this would yield a beneficial effect, or would solely take the self-regulating properties, brought by residual connections, from the model, remains a topic for future research.</p>]]></content><author><name>Anonymous</name></author><summary type="html"><![CDATA[["This blog post provides an interactive journey through a representation analysis in deep and wide neural networks."]]]></summary></entry></feed>